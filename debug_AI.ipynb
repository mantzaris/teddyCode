{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mantzaris/teddyCode/blob/main/debug_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> _Colab Notebook Template_\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). This takes a couple of minutes.\n",
        "4. Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeFXS0F0zww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd791aa7-ed7d-4139-b0bb-1827c4b7bbf0"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.8.2\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\n",
        "  if [ $GPU -eq 1 ]; then\n",
        "    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Julia 1.8.2 on the current Colab Runtime...\n",
            "2022-12-15 21:56:53 URL:https://storage.googleapis.com/julialang2/bin/linux/x64/1.8/julia-1.8.2-linux-x86_64.tar.gz [135859273/135859273] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "Installing Julia package BenchmarkTools...\n",
            "Installing IJulia kernel...\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mInstalling julia kernelspec in /root/.local/share/jupyter/kernels/julia-1.8\n",
            "\n",
            "Successfully installed julia version 1.8.2!\n",
            "Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\n",
            "jump to the 'Checking the Installation' section.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzvvzCl1i0F"
      },
      "source": [
        "import Pkg; Pkg.add(\"Plots\");\n",
        "import Pkg; Pkg.add(\"StatsBase\");\n",
        "import Pkg; Pkg.add(\"InvertedIndices\")\n",
        "import Pkg; Pkg.add(\"Flux\")\n",
        "import Pkg; Pkg.add(\"OneHotArrays\")\n",
        "import Pkg; Pkg.add(\"Graphs\")\n",
        "import Pkg; Pkg.add(\"GraphPlot\")\n",
        "import Pkg; Pkg.add(\"Distributions\")\n",
        "Pkg.add(\"PyCall\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "using Random\n",
        "using InvertedIndices\n",
        "using SparseArrays\n",
        "using StatsBase\n",
        "using LinearAlgebra\n",
        "using Plots\n",
        "using BenchmarkTools\n",
        "using Flux\n",
        "using PyCall\n",
        "using OneHotArrays\n",
        "using Statistics\n",
        "using Graphs\n",
        "using GraphPlot\n",
        "using Distributions\n",
        "np = pyimport(\"numpy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HurkfajGy8eF",
        "outputId": "84afbefe-08be-4db2-e661-5549cb408c23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PyObject <module 'numpy' from '/usr/local/lib/python3.8/dist-packages/numpy/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert adj to S marix\n",
        "function A2S(AdjMat)\n",
        "    AdjMat += I #add the identity to the diagonal, add self-loops\n",
        "    diag = Diagonal(vec(sum(AdjMat,dims=2) .^ (-1/2)))\n",
        "    return (diag) * AdjMat * (diag) #return the normalized S matrix\n",
        "end\n",
        "\n",
        "\n",
        "function create_adjacency_matrix(num, distro)\n",
        "  Random.seed!(10)\n",
        "  ER_tmp = erdos_renyi( num , 10*(num) )\n",
        "  BA_tmp = barabasi_albert( num , 8 )\n",
        "  SF_tmp = static_scale_free( num , 8*(num) , 4 )\n",
        "  WS_tmp = erdos_renyi( num , 10*(num) ) #barabasi_albert( NN_tmp , 5 )\n",
        "  blocks_tmp = blockdiag( blockdiag( blockdiag(ER_tmp,BA_tmp),SF_tmp ), WS_tmp )\n",
        "    \n",
        "  #now add some edges between the blocks that are the communities\n",
        "  for bb in 1:Int(round(num/10))\n",
        "    for b1 in 0:3\n",
        "      for b2 in 0:3\n",
        "        if(b1 < b2)\n",
        "          range1 = randperm(num)[1] + b1*num\n",
        "          range2 = randperm(num)[1] + b2*num\n",
        "          add_edge!( blocks_tmp , range1 , range2 )\n",
        "        end\n",
        "      end\n",
        "    end\n",
        "  end\n",
        "  density_nn = Graphs.density(blocks_tmp)\n",
        "  adj = Matrix(adjacency_matrix(blocks_tmp))\n",
        "\n",
        " \n",
        "  d1 = distro([11 ,5 ,1])\n",
        "  d2 = distro([2, 10, 8])\n",
        "  d3 = distro([2 ,5, 4]) \n",
        "  c1 = Categorical( [0.5,0.25,0.25] )\n",
        "  c2 = Categorical( [0.15,0.15,0.7] )\n",
        "  c3 = Categorical( [0.5,0.5,0] )\n",
        "\n",
        "  xd1 = rand( d1 , num )\n",
        "   xc1 = onehotbatch( rand( c1 , num ) , 1:3 )\n",
        "   x1a = vcat( xd1 , xc1 )'\n",
        "   xd1 = rand( d1 , num )\n",
        "   xc1 = onehotbatch( rand( c1 , num ) , 1:3 )\n",
        "   x1b = vcat( xd1 , xc1 )'\n",
        "   xd2 = rand( d2 , num )\n",
        "   xc2 = onehotbatch( rand( c2 , num ) , 1:3 )\n",
        "   x2 = vcat( xd2 , xc2 )'\n",
        "   xd3 = rand( d3 , num )\n",
        "   xc3 = onehotbatch( rand( c3 , num ) , 1:3 )\n",
        "   x3 = vcat( xd3 , xc3 )'\n",
        "   xc3 = onehotbatch( rand( c3 , num ) , 1:3 )\n",
        "   x3 = vcat( xd3 , xc3 )'\n",
        "\n",
        "  X = vcat( x1a , x1b , x2 , x3 )\n",
        "  y1a = onehotbatch( 1*ones(num) , 1:2 )'\n",
        "  y1b = onehotbatch( 1*ones(num) , 1:2 )'\n",
        "  y2 = onehotbatch( 2*ones(num) , 1:2 )'\n",
        "  y3 = onehotbatch( 2*ones(num) , 1:2 )'\n",
        "  Y = vcat(y1a, y1b, y2, y3)\n",
        "  Y_to_use = vcat(1*ones(num), 1*ones(num), 2*ones(num), 2*ones(num))\n",
        "  return adj, X, Y_to_use\n",
        "end \n",
        "\n",
        "function split_matrix(data, at)\n",
        "    Random.seed!(1)\n",
        "    n =size(data)[2]\n",
        "    idx = shuffle(1:n)\n",
        "    train_idx = view(idx, 1:floor(Int, at*n))\n",
        "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
        "    trained = data[:,train_idx]\n",
        "    tested = data[:,test_idx]\n",
        "    return(trained, tested)\n",
        "end\n",
        "\n",
        "\n",
        "function load_and_train_2(SX_, yhot_, train_x_, train_y_, test_x_, test_y_)\n",
        "  model_ = Chain( Dense( size(SX_, 1) => size(yhot_, 1)) , softmax)\n",
        "  loss(x, y) = Flux.crossentropy(model_(x), y)\n",
        "  opt = Adam(0.01)\n",
        "  pars = Flux.params(model_)\n",
        "  data = Flux.DataLoader((SX_, yhot_) , batchsize = 10 , shuffle = true)\n",
        "  epochs_ = Int64[]\n",
        "  loss_on_train_ = Float32[]\n",
        "  loss_on_test_ = Float32[]\n",
        "  for epoch in 1:500\n",
        "    Flux.train!(loss, pars, data ,opt)\n",
        "    push!(epochs_, epoch)\n",
        "    push!(loss_on_train_, loss(train_x_, train_y_))\n",
        "    push!(loss_on_test_, loss(test_x_, test_y_))\n",
        "  end \n",
        "  return(epochs_, loss_on_train_, loss_on_test_, model_)\n",
        "end \n",
        "\n",
        "\n",
        "function train_3(num, method, distro)\n",
        "  for k in 0:5\n",
        "    ad, x, y = create_adjacency_matrix(num, distro)\n",
        "    yhot = onehotbatch(y, [1, 2])\n",
        "    S = A2S(ad)\n",
        "    SX = S^k * x\n",
        "    SX\n",
        "    SX = SX'\n",
        "    train_x, test_x = split_matrix(SX, 0.7)\n",
        "    train_y, test_y = split_matrix(yhot, 0.7)\n",
        "    if method == 0\n",
        "      #println(\"Training with raw data\")\n",
        "      epochs, loss_on_train, loss_on_test,  model = load_and_train_2(SX, yhot, train_x, train_y, test_x, test_y)\n",
        "    end\n",
        "\n",
        "      accuracy = round(mean( onecold( model(train_x), [1, 2] ) .== onecold(train_y, [1, 2]) ) * 100, digits = 3)\n",
        "      println(\"Accuracy: \", accuracy, \"%\", \", k = $k, diatribution = $distro\")\n",
        "    \n",
        "    \n",
        "      #plot(epochs, loss_on_train, label = \"loss on train\")\n",
        "      #plot!(epochs, loss_on_test, label = \"loss on test\")\n",
        "  end\n",
        "end "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjM_qq54lCcs",
        "outputId": "065d0ad0-6308-4c49-cacf-6eb558b95db9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train_3 (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = [MvNormalCanon, MvNormal, MvLogNormal, Dirichlet ]\n",
        "for i in l\n",
        "  train_3(250, 0, i)\n",
        "end "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx9JwGANzJU-",
        "outputId": "9b19872b-a4a7-46de-bff5-225d74d34e41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 59.143%, k = 0, diatribution = MvNormalCanon\n",
            "Accuracy: 79.714%, k = 1, diatribution = MvNormalCanon\n",
            "Accuracy: 98.429%, k = 2, diatribution = MvNormalCanon\n",
            "Accuracy: 100.0%, k = 3, diatribution = MvNormalCanon\n",
            "Accuracy: 100.0%, k = 4, diatribution = MvNormalCanon\n",
            "Accuracy: 100.0%, k = 5, diatribution = MvNormalCanon\n",
            "Accuracy: 55.0%, k = 0, diatribution = MvNormal\n",
            "Accuracy: 77.857%, k = 1, diatribution = MvNormal\n",
            "Accuracy: 97.429%, k = 2, diatribution = MvNormal\n",
            "Accuracy: 100.0%, k = 3, diatribution = MvNormal\n",
            "Accuracy: 100.0%, k = 4, diatribution = MvNormal\n",
            "Accuracy: 100.0%, k = 5, diatribution = MvNormal\n",
            "Accuracy: 56.857%, k = 0, diatribution = MvLogNormal\n",
            "Accuracy: 96.286%, k = 1, diatribution = MvLogNormal\n",
            "Accuracy: 49.429%, k = 2, diatribution = MvLogNormal\n",
            "Accuracy: 49.429%, k = 3, diatribution = MvLogNormal\n",
            "Accuracy: 49.429%, k = 4, diatribution = MvLogNormal\n",
            "Accuracy: 49.429%, k = 5, diatribution = MvLogNormal\n",
            "Accuracy: 98.857%, k = 0, diatribution = Dirichlet\n",
            "Accuracy: 100.0%, k = 1, diatribution = Dirichlet\n",
            "Accuracy: 100.0%, k = 2, diatribution = Dirichlet\n",
            "Accuracy: 100.0%, k = 3, diatribution = Dirichlet\n",
            "Accuracy: 100.0%, k = 4, diatribution = Dirichlet\n",
            "Accuracy: 100.0%, k = 5, diatribution = Dirichlet\n"
          ]
        }
      ]
    }
  ]
}